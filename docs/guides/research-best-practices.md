# AI調査・リサーチ ベストプラクティス

> AIエージェント（特にClaude Code）を使った調査の進め方。

## 早見表

| 知りたいこと | 詳細 |
|---|:---:|
| 市場・競合調査のやり方 | [>>](#市場競合調査) |
| 技術調査の注意点 | [>>](#技術調査) |
| コードベース調査の方法 | [>>](#コードベース調査) |
| 調査結果のまとめ方 | [>>](#調査結果のフォーマット) |
| 調査→仕様→開発のつなぎ方 | [>>](#spec-driven-development) |
| 5つの原則 | [>>](#調査リサーチの5原則) |

---

## 市場・競合調査

### 調べるべき観点

- **市場規模・成長率**: TAM/SAM/SOMの推定、CAGR予測
- **競合マップ**: 主要プレイヤーの市場シェア、製品ポートフォリオ、差別化ポイント
- **トレンド分析**: 技術動向、規制動向、顧客ニーズの変化
- **SWOT分析**: 各競合の強み・弱み・機会・脅威

### AIへの効果的な指示

ペルソナ設定が鍵。具体的な役割を与えると出力の質が上がる:

```
あなたはB2B SaaSを専門とするシニアマーケットリサーチアナリストです。
[競合X]の最近のプロダクトアップデートを分析し、拡大戦略を特定してください。
```

### 注意点

- AIの知識にはカットオフがある。最新の市場データはWeb検索MCPで補完
- AIが生成した市場データの数値は必ず一次ソースで裏取りする

---

## 技術調査

### AIに技術選定を任せるときの注意点

**知識カットオフ問題が最大のリスク。** カットオフ以降のライブラリバージョンや新機能は正確に把握していない可能性がある。

### 多層防御アプローチ

| 対策 | 方法 | 例 |
|---|---|---|
| プロンプト設計 | 不確実さを明示させる | 「確信がない場合は『不明』と回答して」 |
| Web検索併用 | MCP経由でリアルタイム情報取得 | Brave Search / Google CSE MCP |
| 人間による検証 | AIの出力を一次ソースで裏取り | npm/PyPI公式ページ、GitHub |
| PoC作成 | 小さな検証コードを書かせる | 候補ライブラリの動作確認 |

### 検証ステップ

1. AIに候補を3-5個リストアップさせる
2. Web検索で最新情報を補完（npm trends、GitHub Stars、最終更新日）
3. 公式ドキュメントのURLを渡して最新情報を読ませる
4. 小さなPoCを書かせて動作確認
5. 存在しないAPI名やメソッドがないか公式リファレンスと照合

---

## コードベース調査

### 4ステップで理解する

**Step 1: 全体概要を掴む**
```
このコードベースの概要を教えて
メインのアーキテクチャパターンは？
主要なデータモデルは？
```

**Step 2: 特定のコードを探す**
```
ユーザー認証を処理するファイルを見つけて
これらの認証ファイルはどう連携している？
```

**Step 3: 実行フローを追跡する**
```
ログインプロセスをフロントエンドからデータベースまで追って
```

**Step 4: 深掘りする**
```
ExecutionFactoryのgit履歴を調べて、そのAPIがどう形成されたか要約して
```

### 影響範囲の分析

```
この関数を変更した場合の影響範囲を分析して。
呼び出し元を全て特定し、各呼び出し元で破壊的変更になるか判定して。
```

subagentで並列調査するとメインのコンテキストを汚さない:
```
subagentを使って、認証、データベース層、APIモジュールを並列で調査して
```

---

## 調査結果のフォーマット

```markdown
# 調査レポート: [テーマ名]

## 1. エグゼクティブサマリー
- 結論（1-3文）
- 推奨アクション

## 2. 調査背景・目的
- なぜこの調査が必要か
- 調査範囲（スコープ）

## 3. 調査結果
### 3.1 [観点1]
- 事実（ソース付き）
- 分析

### 3.2 [観点2]
- 事実（ソース付き）
- 分析

## 4. 比較表（該当する場合）
| 基準 | 選択肢A | 選択肢B | 選択肢C |
|------|---------|---------|---------|

## 5. 推奨事項
- 推奨する選択肢と理由
- リスクと緩和策

## 6. 次のステップ
- [ ] アクションアイテム1
- [ ] アクションアイテム2

## 7. 情報源
- 参照したURL、ドキュメント
```

---

## Spec-Driven Development

2025年に台頭したパターン。調査→仕様→開発の流れを明確にする。

### フロー

```
調査（Plan Mode）→ RESEARCH.md → SPEC.md → PLAN.md → /clear → 新セッションで実装
```

### なぜ新セッションで実装するのか

- クリーンなコンテキストにより実装に集中できる
- 調査フェーズのノイズ（大量のファイル読み取り、失敗した探索）が残らない
- 書かれた仕様書を参照する形でブレなく実装できる

### インタビュー式の要件定義

```
[簡潔な説明]を構築したい。AskUserQuestionツールを使って詳しくインタビューして。
技術的な実装、UI/UX、エッジケース、懸念事項、トレードオフについて質問して。
自明な質問はしないで、自分が考えていない難しい部分を掘り下げて。
全てカバーしたらSPEC.mdに完全な仕様を書いて。
```

### ファイル構成

- `RESEARCH.md` — 調査結果レポート
- `SPEC.md` — 機能仕様（スコープ、意図、制約）
- `PLAN.md` — 実装計画（ステップ）

---

## 調査リサーチの5原則

1. **探索と実行を分離する** — Plan Modeで調査、Normal Modeで実装。調査結果は必ずファイルに書き出す
2. **コンテキストを管理する** — subagentで調査を委譲し、メインのコンテキストウィンドウを守る
3. **AIの限界を補完する** — 知識カットオフ以降はWeb検索MCPで補い、ハルシネーションは一次ソースで検証
4. **構造化アウトプットを求める** — 比較表、推奨事項、次のステップを含む構造化レポートを要求
5. **調査→仕様→実装の接続を明確にする** — RESEARCH.md → SPEC.md → PLAN.md → 新セッションで実装

---

## 参考ツール・リソース

| ツール | 用途 |
|---|---|
| [Deep Research Skill](https://github.com/199-biotechnologies/claude-deep-research-skill) | Claude Code用 8フェーズ調査パイプライン |
| [GitHub Spec Kit](https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with-a-new-open-source-toolkit/) | Spec-Driven Development ツールキット |
| Brave Search MCP | Web検索で最新情報を補完 |
| GitHub MCP | Issue、PR、コードの検索・分析 |

## 出典

- [Claude Code Best Practices](https://code.claude.com/docs/en/best-practices)
- [Spec-driven development (ThoughtWorks)](https://www.thoughtworks.com/en-us/insights/blog/agile-engineering-practices/spec-driven-development-unpacking-2025-new-engineering-practices)
- [Spec-driven development with AI (GitHub Blog)](https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with-a-new-open-source-toolkit/)
